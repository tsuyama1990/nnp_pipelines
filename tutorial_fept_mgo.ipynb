{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e37e02",
   "metadata": {},
   "source": [
    "# FePt/MgO Interface Learning Tutorial\n",
    "\n",
    "This tutorial demonstrates a multi-stage active learning strategy to simulate a FePt (metal) and MgO (insulator) interface using the `nnp_pipelines` codebase.\n",
    "\n",
    "We will follow a 4-step workflow:\n",
    "1. **Learn FePt (Metallic Phase)**: Generate initial data and train a base FePt potential.\n",
    "2. **Learn MgO (Ionic Phase)**: Generate initial data and train a separate MgO potential.\n",
    "3. **Interface Construction & Knowledge Transfer**: Build interface structures, label them, merge datasets, and train an \"Interface Potential\".\n",
    "4. **Active Learning Loop**: Initialize the active learning orchestrator with the interface potential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import shutil\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from ase.io import read, write\n",
    "\n",
    "from shared.core.config import Config\n",
    "from shared.autostructure.interface import InterfaceBuilder\n",
    "from orchestrator.workflows.seed_generation import SeedGenerator\n",
    "from orchestrator.src.wrappers.dft_wrapper import DftWorker\n",
    "from orchestrator.src.wrappers.pace_wrapper import PaceWorker\n",
    "from orchestrator.workflows.orchestrator import ActiveLearningOrchestrator\n",
    "from orchestrator.src.factory import ComponentFactory\n",
    "from orchestrator.src.services.al_service import ActiveLearningService\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"InterfaceTutorial\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "Path(\"output\").mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f2780",
   "metadata": {},
   "source": [
    "## Step 1: Learn FePt (Metallic Phase)\n",
    "\n",
    "First, we define a helper function to generate `config.yaml` files dynamically. Then, we run the `SeedGenerator` for Fe and Pt using the \"metallic\" crystal type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d06cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config(filename, elements, crystal_type):\n",
    "    \"\"\"\n",
    "    Helper function to generate config.yaml files dynamically.\n",
    "    \"\"\"\n",
    "    # Load base config\n",
    "    if not Path(\"config.yaml\").exists():\n",
    "        raise FileNotFoundError(\"Base config.yaml not found!\")\n",
    "        \n",
    "    with open(\"config.yaml\", \"r\") as f:\n",
    "        base_config = yaml.safe_load(f)\n",
    "\n",
    "    # Update MD parameters\n",
    "    base_config[\"md_params\"][\"elements\"] = elements\n",
    "    \n",
    "    # Set atomic masses (approximate values)\n",
    "    mass_map = {\n",
    "        \"Fe\": 55.845, \"Pt\": 195.084,\n",
    "        \"Mg\": 24.305, \"O\": 15.999\n",
    "    }\n",
    "    base_config[\"md_params\"][\"masses\"] = {el: mass_map.get(el, 1.0) for el in elements}\n",
    "    \n",
    "    # Update Seed Generation parameters\n",
    "    base_config[\"seed_generation\"][\"crystal_type\"] = crystal_type\n",
    "    base_config[\"seed_generation\"][\"n_random_structures\"] = 10  # Reduced for tutorial speed\n",
    "    base_config[\"seed_generation\"][\"n_samples_for_dft\"] = 5     # Reduced for tutorial speed\n",
    "    base_config[\"seed_generation\"][\"exploration_temperatures\"] = [300.0]\n",
    "\n",
    "    # Update Pacemaker parameters\n",
    "    base_config[\"ace_model\"][\"pacemaker_config\"][\"potential\"][\"elements\"] = elements\n",
    "    base_config[\"ace_model\"][\"pacemaker_config\"][\"potential\"][\"embeddings\"] = {\n",
    "        el: {\"npot\": \"FinnisSinclair\", \"fs_parameters\": [1, 1, 1, 0.5], \"ndensity\": 1} \n",
    "        for el in elements\n",
    "    }\n",
    "\n",
    "    # Save to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        yaml.dump(base_config, f)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def run_seed_generation(elements, crystal_type, phase_name):\n",
    "    \"\"\"\n",
    "    Runs SeedGenerator for a specific phase and manages output files.\n",
    "    \"\"\"\n",
    "    logger.info(f\"--- Starting Phase: {phase_name} ---\")\n",
    "    config_file = f\"config_{phase_name}.yaml\"\n",
    "    create_config(config_file, elements, crystal_type)\n",
    "    \n",
    "    # Initialize Config object\n",
    "    config = Config.from_yaml(config_file)\n",
    "    \n",
    "    # Initialize SeedGenerator\n",
    "    # We assume 'constant.yaml' serves as the meta_config or base reference\n",
    "    meta_config_path = Path(\"constant.yaml\")\n",
    "    if not meta_config_path.exists():\n",
    "        # Create a dummy if it doesn't exist for the tutorial to run without errors\n",
    "        with open(meta_config_path, 'w') as f:\n",
    "            yaml.dump({'lj_params': {'epsilon': 1.0, 'sigma': 2.0}}, f)\n",
    "\n",
    "    generator = SeedGenerator(config, Path(config_file), meta_config_path)\n",
    "    \n",
    "    try:\n",
    "        # Run generation\n",
    "        generator.run()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Seed generation failed for {phase_name}: {e}\")\n",
    "        # Note: In a real run without Docker/Workers set up, this will fail.\n",
    "        # We catch it here to allow the tutorial flow to proceed conceptually.\n",
    "        pass\n",
    "\n",
    "    # Rename outputs to avoid overwriting\n",
    "    output_pot = Path(f\"data/{phase_name}_potential.yace\")\n",
    "    source_pot = Path(\"data/seed/seed_potential.yace\")\n",
    "    \n",
    "    if source_pot.exists():\n",
    "        shutil.move(source_pot, output_pot)\n",
    "        logger.info(f\"Saved potential to {output_pot}\")\n",
    "    else:\n",
    "        logger.warning(f\"No potential generated for {phase_name} (expected if workers are offline).\")\n",
    "    \n",
    "    # Find and rename the dataset\n",
    "    data_dir = Path(\"data\")\n",
    "    datasets = list(data_dir.glob(\"seed_dataset_*.pckl.gzip\"))\n",
    "    target_dataset = None\n",
    "    \n",
    "    if datasets:\n",
    "        # Sort by modification time to get the latest\n",
    "        latest_dataset = max(datasets, key=os.path.getmtime)\n",
    "        target_dataset = data_dir / f\"{phase_name}_dataset.pckl.gzip\"\n",
    "        shutil.move(latest_dataset, target_dataset)\n",
    "        logger.info(f\"Saved dataset to {target_dataset}\")\n",
    "        \n",
    "    return output_pot, target_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for FePt\n",
    "fept_pot, fept_data = run_seed_generation([\"Fe\", \"Pt\"], \"metallic\", \"fept\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05da85a",
   "metadata": {},
   "source": [
    "## Step 2: Learn MgO (Ionic Phase)\n",
    "\n",
    "Now we repeat the process for Mg and O using the \"ionic\" crystal type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for MgO\n",
    "mgo_pot, mgo_data = run_seed_generation([\"Mg\", \"O\"], \"ionic\", \"mgo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b7772",
   "metadata": {},
   "source": [
    "## Step 3: Interface Construction & Knowledge Transfer\n",
    "\n",
    "We use the `InterfaceBuilder` to generate diverse interface structures between FePt and MgO. Then we label these structures using DFT, merge the datasets, and train a unified interface potential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"--- Starting Interface Construction ---\")\n",
    "\n",
    "# Placeholder logic if data generation failed (for tutorial robustness)\n",
    "if not fept_data or not mgo_data:\n",
    "    logger.warning(\"Skipping interface construction due to missing data from previous steps.\")\n",
    "    # For demonstration, we create dummy files if they don't exist\n",
    "    # (In a real scenario, you would debug why generation failed)\n",
    "else:\n",
    "    # Load datasets\n",
    "    df_fept = pd.read_pickle(fept_data, compression=\"gzip\")\n",
    "    df_mgo = pd.read_pickle(mgo_data, compression=\"gzip\")\n",
    "    \n",
    "    # Pick a sample structure from each\n",
    "    struct_fept = df_fept.iloc[-1][\"ase_atoms\"]\n",
    "    struct_mgo = df_mgo.iloc[-1][\"ase_atoms\"]\n",
    "    \n",
    "    # Initialize InterfaceBuilder\n",
    "    builder = InterfaceBuilder(struct_fept, struct_mgo)\n",
    "    \n",
    "    # Generate structures (Strain, Twist, Intermix)\n",
    "    interface_structures = builder.generate_all()\n",
    "    logger.info(f\"Generated {len(interface_structures)} interface structures.\")\n",
    "    \n",
    "    # Save candidates for labeling\n",
    "    interface_file = \"data/interface_candidates.xyz\"\n",
    "    write(interface_file, interface_structures)\n",
    "    \n",
    "    # --- Labeling ---\n",
    "    interface_elements = [\"Fe\", \"Pt\", \"Mg\", \"O\"]\n",
    "    interface_config_file = \"config_interface.yaml\"\n",
    "    create_config(interface_config_file, interface_elements, \"metallic\")\n",
    "    \n",
    "    dft_worker = DftWorker(Path(\"data\"))\n",
    "    labeled_interface_file = \"interface_labeled.xyz\"\n",
    "    \n",
    "    logger.info(\"Labeling interface structures...\")\n",
    "    # dft_worker.label calls the DFT container\n",
    "    try:\n",
    "        dft_worker.label(interface_config_file, \"constant.yaml\", \"interface_candidates.xyz\", labeled_interface_file)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Labeling failed: {e}\")\n",
    "\n",
    "    # --- Data Merging ---\n",
    "    if Path(f\"data/{labeled_interface_file}\").exists():\n",
    "        labeled_interface_atoms = read(Path(\"data\") / labeled_interface_file, index=\":\")\n",
    "        df_interface = pd.DataFrame({\"ase_atoms\": labeled_interface_atoms})\n",
    "        \n",
    "        logger.info(\"Merging datasets (FePt + MgO + Interface)...\")\n",
    "        combined_df = pd.concat([df_fept, df_mgo, df_interface], ignore_index=True)\n",
    "        \n",
    "        combined_dataset_path = Path(\"data/combined_interface.pckl.gzip\")\n",
    "        combined_df.to_pickle(combined_dataset_path, compression=\"gzip\")\n",
    "        \n",
    "        # --- Train Interface Potential ---\n",
    "        logger.info(\"Training Interface Potential...\")\n",
    "        pace_worker = PaceWorker(Path(\"data\"))\n",
    "        \n",
    "        try:\n",
    "            interface_pot_name = pace_worker.train(\n",
    "                interface_config_file,\n",
    "                \"constant.yaml\",\n",
    "                combined_dataset_path.name,\n",
    "                iteration=1\n",
    "            )\n",
    "            interface_pot_path = Path(\"data\") / interface_pot_name\n",
    "            logger.info(f\"Interface Potential trained: {interface_pot_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training failed: {e}\")\n",
    "            interface_pot_path = None\n",
    "    else:\n",
    "        logger.warning(\"No labeled interface data found. Skipping merging/training.\")\n",
    "        interface_pot_path = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981059d",
   "metadata": {},
   "source": [
    "## Step 4: Active Learning Loop\n",
    "\n",
    "Finally, we configure the `ActiveLearningOrchestrator` to start with the \"Interface Potential\" created in Step 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9559b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"--- Starting Active Learning Loop ---\")\n",
    "\n",
    "# Configuration for AL Loop\n",
    "al_config_file = \"config_al.yaml\"\n",
    "# Ensure we have the interface elements\n",
    "create_config(al_config_file, [\"Fe\", \"Pt\", \"Mg\", \"O\"], \"metallic\")\n",
    "\n",
    "# Load and customize AL config\n",
    "with open(al_config_file, \"r\") as f:\n",
    "    al_config = yaml.safe_load(f)\n",
    "\n",
    "# Set initial potential\n",
    "if 'interface_pot_path' in locals() and interface_pot_path and interface_pot_path.exists():\n",
    "    al_config[\"al_params\"][\"initial_potential\"] = interface_pot_path.name\n",
    "else:\n",
    "    logger.warning(\"Using default/dummy potential path for AL initialization.\")\n",
    "    al_config[\"al_params\"][\"initial_potential\"] = \"dummy_potential.yace\"\n",
    "\n",
    "# Set initial structure (use one of the generated interface structures if available)\n",
    "initial_struct_name = \"initial_interface.data\"\n",
    "if 'interface_structures' in locals() and interface_structures:\n",
    "    write(Path(\"data\") / initial_struct_name, interface_structures[0], format=\"lammps-data\")\n",
    "    al_config[\"md_params\"][\"initial_structure\"] = initial_struct_name\n",
    "else:\n",
    "    # Create a dummy structure file so the factory doesn't crash during init\n",
    "    with open(Path(\"data\") / initial_struct_name, 'w') as f:\n",
    "        f.write(\"Dummy LAMMPS data file\")\n",
    "    al_config[\"md_params\"][\"initial_structure\"] = initial_struct_name\n",
    "\n",
    "# Save config\n",
    "with open(al_config_file, \"w\") as f:\n",
    "    yaml.dump(al_config, f)\n",
    "\n",
    "# Initialize Components\n",
    "try:\n",
    "    config_al = Config.from_yaml(al_config_file)\n",
    "    component_factory = ComponentFactory(config_al)\n",
    "    \n",
    "    # Create AL Service\n",
    "    al_service = ActiveLearningService(config_al, Path(al_config_file), Path(\"constant.yaml\"))\n",
    "    \n",
    "    # Create Explorer\n",
    "    explorer = component_factory.create_explorer()\n",
    "    \n",
    "    # Instantiate Orchestrator\n",
    "    orchestrator = ActiveLearningOrchestrator(config_al, al_service, explorer)\n",
    "    \n",
    "    logger.info(\"ActiveLearningOrchestrator initialized successfully.\")\n",
    "    # To run the loop:\n",
    "    # orchestrator.run()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize AL Orchestrator: {e}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
